{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "598366e3-e639-46b2-80f7-8862b312077b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6346300533943554,\n",
       " '              precision    recall  f1-score   support\\n\\n       False       0.63      0.94      0.76       791\\n        True       0.65      0.17      0.28       520\\n\\n    accuracy                           0.63      1311\\n   macro avg       0.64      0.56      0.52      1311\\nweighted avg       0.64      0.63      0.57      1311\\n',\n",
       " array([[741,  50],\n",
       "        [429,  91]], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data_linear_features(data, feature_prefix, target_column, test_ratio=0.25, imputer_strategy=\"median\"):\n",
    "    \"\"\"\n",
    "    Preprocesses the data, including imputation and splitting, without polynomial feature augmentation.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The entire dataset.\n",
    "    - feature_prefix: Prefix for feature columns.\n",
    "    - target_column: Name of the target column.\n",
    "    - test_ratio: Ratio for test set splitting.\n",
    "    - imputer_strategy: Strategy to use for imputation ('mean', 'median', etc.)\n",
    "    \n",
    "    Returns:\n",
    "    - X_train, y_train: Training data and labels\n",
    "    - X_test, y_test: Test data and labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    feature_cols = [col for col in data.columns if feature_prefix in col]\n",
    "    X = data[feature_cols]\n",
    "    y = data[target_column].astype(bool)\n",
    "\n",
    "    # Impute missing values\n",
    "\n",
    "    # Split the data into training and test sets\n",
    "    train_size = int((1 - test_ratio) * len(data))\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "def train_and_evaluate_classifier(X_train, y_train, X_test, y_test, classifier, imputer_strategy=\"median\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a classifier given training and test data.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train, y_train: Training data and labels\n",
    "    - X_test, y_test: Test data and labels\n",
    "    - classifier: The machine learning classifier to be trained\n",
    "    - imputer_strategy: Strategy to use for imputation ('mean', 'median', etc.)\n",
    "    \n",
    "    Returns:\n",
    "    - accuracy: Accuracy of the classifier on the test set\n",
    "    - report: Classification report\n",
    "    - conf_matrix: Confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Impute missing values in the training and test sets\n",
    "\n",
    "    # Create a pipeline with data scaling and the classifier\n",
    "    pipeline = make_pipeline(StandardScaler(), classifier)\n",
    "\n",
    "    # Convert target variables to boolean type\n",
    "    y_train = y_train.astype(bool)\n",
    "    y_test = y_test.astype(bool)\n",
    "\n",
    "    # Train the classifier using the imputed data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, report, conf_matrix\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "data = pd.read_csv(\"eth1h_withlabel_andfeatures.csv\").dropna()\n",
    "# Preprocess the data with imputation without polynomial feature augmentation\n",
    "X_train_linear, y_train, X_test_linear, y_test = preprocess_data_linear_features(data, \"Feature\", \"label\", test_ratio=0.25)\n",
    "\n",
    "# Train and evaluate the SVM classifier using only linear features\n",
    "accuracy_linear, report_linear, conf_matrix_linear = train_and_evaluate_classifier(\n",
    "    X_train_linear, y_train, X_test_linear, y_test, SVC())\n",
    "\n",
    "accuracy_linear, report_linear, conf_matrix_linear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd1e95e-8db4-4dbb-a12c-85f5e4ed4166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[888, 119],\n",
       "       [467,  99]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a648ff22-c88d-4ec2-b06b-7079edd4021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.0-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\xyz\\anaconda3\\envs\\basic\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\xyz\\anaconda3\\envs\\basic\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\xyz\\anaconda3\\envs\\basic\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.0 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c842d9e-287b-44dd-bfa6-6b6bf5168b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
