{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a05281-6a05-4b16-8a9d-d1fc798a6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Open time     Open     High      Low    Close      Volume  \\\n",
      "0  1676988000000  1669.88  1684.93  1668.00  1674.47  287928.579   \n",
      "1  1676991600000  1674.47  1677.39  1656.50  1671.83  327047.798   \n",
      "2  1676995200000  1671.83  1674.11  1655.00  1661.63  298489.158   \n",
      "3  1676998800000  1661.62  1677.63  1661.07  1677.17  143808.598   \n",
      "4  1677002400000  1677.16  1686.80  1672.35  1679.28  228363.095   \n",
      "\n",
      "      Close time  Quote asset volume  Number of trades  \\\n",
      "0  1676991599999        4.828528e+08          179930.0   \n",
      "1  1676995199999        5.455276e+08          205255.0   \n",
      "2  1676998799999        4.967755e+08          173259.0   \n",
      "3  1677002399999        2.398557e+08          103208.0   \n",
      "4  1677005999999        3.835786e+08          141153.0   \n",
      "\n",
      "   Taker buy base asset volume  Taker buy quote asset volume  Ignore  \\\n",
      "0                   151763.602                  2.545146e+08     0.0   \n",
      "1                   156739.585                  2.614559e+08     0.0   \n",
      "2                   132042.199                  2.197751e+08     0.0   \n",
      "3                    77953.952                  1.300111e+08     0.0   \n",
      "4                   126986.281                  2.133271e+08     0.0   \n",
      "\n",
      "             Open_time           Close_time  \n",
      "0  2023-02-21 14:00:00  2023-02-21 14:59:59  \n",
      "1  2023-02-21 15:00:00  2023-02-21 15:59:59  \n",
      "2  2023-02-21 16:00:00  2023-02-21 16:59:59  \n",
      "3  2023-02-21 17:00:00  2023-02-21 17:59:59  \n",
      "4  2023-02-21 18:00:00  2023-02-21 18:59:59  \n",
      "          Open time     Open     High      Low    Close     Volume  \\\n",
      "4314  1692518400000  1665.00  1668.87  1662.56  1668.29  43936.229   \n",
      "4315  1692522000000  1668.29  1669.90  1666.04  1669.70  25778.054   \n",
      "4316  1692525600000  1669.70  1672.00  1668.43  1671.54  44918.421   \n",
      "4317  1692529200000  1671.54  1674.98  1670.61  1674.01  50335.114   \n",
      "4318  1692532800000  1674.02  1674.84  1671.52  1671.98  17324.925   \n",
      "\n",
      "         Close time  Quote asset volume  Number of trades  \\\n",
      "4314  1692521999999        7.319934e+07           39489.0   \n",
      "4315  1692525599999        4.299822e+07           26849.0   \n",
      "4316  1692529199999        7.502363e+07           38179.0   \n",
      "4317  1692532799999        8.420316e+07           45712.0   \n",
      "4318  1692536399999        2.898276e+07           14849.0   \n",
      "\n",
      "      Taker buy base asset volume  Taker buy quote asset volume  Ignore  \\\n",
      "4314                    22373.452                  3.727792e+07     0.0   \n",
      "4315                    14255.705                  2.378029e+07     0.0   \n",
      "4316                    24520.356                  4.095306e+07     0.0   \n",
      "4317                    24340.217                  4.071953e+07     0.0   \n",
      "4318                     6135.105                  1.026414e+07     0.0   \n",
      "\n",
      "                Open_time           Close_time  \n",
      "4314  2023-08-20 08:00:00  2023-08-20 08:59:59  \n",
      "4315  2023-08-20 09:00:00  2023-08-20 09:59:59  \n",
      "4316  2023-08-20 10:00:00  2023-08-20 10:59:59  \n",
      "4317  2023-08-20 11:00:00  2023-08-20 11:59:59  \n",
      "4318  2023-08-20 12:00:00  2023-08-20 12:59:59  \n",
      "timerange 4752\n",
      "training from 2023-02-04 03:00:00\n",
      "training till 2023-08-20 00:00:00\n",
      "Models saved with timestamp 20230821_162650\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "src_repo = r\"C:\\Users\\xyz\\Desktop\\bodi2\\awesome0\\src\"\n",
    "sys.path.append(src_repo)\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from BinanceDataDownload import fetch_binance_data\n",
    "from config import *\n",
    "from extractLastFeaturesForClfTraining import *\n",
    "from datalabelling import add_labels\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from config import *\n",
    "\n",
    "def most_recent_file(directory, prefix):\n",
    "    \"\"\"Returns the most recently created file in the given directory with the specified prefix.\"\"\"\n",
    "    files = [f for f in os.listdir(directory) if f.startswith(prefix)]\n",
    "    if not files:\n",
    "        return None\n",
    "    return max([os.path.join(directory, f) for f in files], key=os.path.getctime)\n",
    "\n",
    "def train_and_save_models(clf_dir, symbol='ETHUSDT', timeframe='1h', retrain_time=datetime.timedelta(weeks=1)):\n",
    "    \n",
    "    recent_svc = most_recent_file(clf_dir, \"signal_clf_\")\n",
    "    recent_lof = most_recent_file(clf_dir, \"novelty_detection_\")\n",
    "    \n",
    "    retrain = False\n",
    "    \n",
    "    for model in [recent_svc, recent_lof]:\n",
    "        if not model:\n",
    "            retrain = True\n",
    "            break\n",
    "        \n",
    "        date_str = re.search(r'(\\d{4}\\d{2}\\d{2}_\\d{2}\\d{2}\\d{2})', model)\n",
    "        if date_str:\n",
    "            recent_date = datetime.datetime.strptime(date_str.group(1), '%Y%m%d_%H%M%S')\n",
    "            \n",
    "            # Überprüfen, ob retrain_time seit dem letzten Training vergangen ist\n",
    "            if datetime.datetime.now() - recent_date > retrain_time:\n",
    "                retrain = True\n",
    "                break\n",
    "    \n",
    "    if not retrain:\n",
    "        print(\"No retraining required!\")\n",
    "        return\n",
    "    \n",
    "    # Daten von Binance herunterladen\n",
    "    timerange = TRAIN_WINDOW_SIZE + 2 * max(feature_lookbacks)\n",
    "    print(\"timerange\", timerange)\n",
    "    df = fetch_binance_data(symbol=symbol, timeframe=timeframe, timerange=timerange)\n",
    "    \n",
    "    # Features und Labels extrahieren\n",
    "    df_with_feats = integrate_features_to_df(df)\n",
    "    df_with_feats_and_labels = add_labels(df_with_feats)\n",
    "    \n",
    "    # Daten vorbereiten\n",
    "    df_with_feats_and_labels = df_with_feats_and_labels.dropna(subset=['label'])\n",
    "    \n",
    "    print(\"training from\",df_with_feats_and_labels.iloc[0].Open_time )\n",
    "    print(\"training till\",df_with_feats_and_labels.iloc[-1].Open_time )\n",
    "    X = df_with_feats_and_labels[[col for col in df_with_feats_and_labels.columns if 'Feature' in col]]\n",
    "    y = df_with_feats_and_labels['label']\n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    # SVC-Classifier trainieren\n",
    "    svc_model = train_model_wf(X, y)\n",
    "    \n",
    "    # LOF-Modell trainieren\n",
    "    lof_model = train_lof_model(X)\n",
    "    \n",
    "    # Beide Modelle speichern\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    joblib.dump(svc_model, os.path.join(clf_dir, f\"signal_clf_{timestamp}.pkl\"))\n",
    "    joblib.dump(lof_model, os.path.join(clf_dir, f\"novelty_detection_{timestamp}.pkl\"))\n",
    "    print(f\"Models saved with timestamp {timestamp}\")\n",
    "\n",
    "\n",
    "def train_model_wf(X_train, y_train):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(max_iter=1000000))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    return pipe\n",
    "\n",
    "def train_lof_model(X_train, contamination=0.0025):\n",
    "    lof = LocalOutlierFactor(novelty=True, contamination=contamination)\n",
    "    lof.fit(X_train)\n",
    "    return lof\n",
    "\n",
    "# Beispielaufruf:\n",
    "test_dir = \"testdir\"\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "retrain_time = datetime.timedelta(seconds=1)\n",
    "train_and_save_models(clf_dir=test_dir, symbol='ETHUSDT', timeframe='1h', retrain_time=retrain_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e995c7e-537e-4595-8f0a-f8439cc07aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testdir'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4e2f3f4-dc7a-45c3-8d1f-7a124f3a2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b03dcf64-d4ff-49e1-ae36-40fa8eaad184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recent_models(clf_dir):\n",
    "    \"\"\"Load the most recent SVC and LOF models from the specified directory.\"\"\"\n",
    "\n",
    "    # Determine the most recent SVC and LOF models based on their filename prefixes\n",
    "    recent_svc_file = most_recent_file(clf_dir, \"signal_clf_\")\n",
    "    recent_lof_file = most_recent_file(clf_dir, \"novelty_detection_\")\n",
    "\n",
    "    if not recent_svc_file or not recent_lof_file:\n",
    "        print(\"Could not find models in the specified directory!\")\n",
    "        return None, None\n",
    "\n",
    "    # Load the models using joblib\n",
    "    svc_model = joblib.load(recent_svc_file)\n",
    "    lof_model = joblib.load(recent_lof_file)\n",
    "\n",
    "    return svc_model, lof_model\n",
    "\n",
    "svc_model, lof_model = load_recent_models(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec2b334-d00c-42fe-8611-0a4ce8ad35f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xyz\\anaconda3\\envs\\basic\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lof_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25bbdb9-36b9-49d8-96c6-525c9e6278b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_feats = integrate_features_to_df(df[[\"Close\", \"Volume\"]])\n",
    "df[\"Close\"] = df.Close.astype(\"float\")\n",
    "df[\"Volume\"] = df.Volume.astype(float)\n",
    "df_with_feats = integrate_features_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de974b37-a59a-4630-b995-a65d2a1bf1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      39427.524\n",
       "1      38991.601\n",
       "2      49293.709\n",
       "3      28408.226\n",
       "4      15179.287\n",
       "         ...    \n",
       "145    21764.488\n",
       "146    43936.229\n",
       "147    25778.054\n",
       "148    44918.421\n",
       "149    15865.812\n",
       "Name: Volume, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b84e052-d421-4302-a23f-257413396c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close time',\n",
       "       'Quote asset volume', 'Number of trades', 'Taker buy base asset volume',\n",
       "       'Taker buy quote asset volume', 'Ignore', 'Open_time', 'Close_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns#.drop(\"Opentime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061551fd-6fc4-4215-9754-3325f00d77dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
