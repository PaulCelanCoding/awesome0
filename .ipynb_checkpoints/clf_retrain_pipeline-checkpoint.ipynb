{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7a05281-6a05-4b16-8a9d-d1fc798a6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No retraining required!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from BinanceDataDownload import fetch_binance_data\n",
    "from config import *\n",
    "from extractLastFeaturesForClfTraining import *\n",
    "from datalabelling import add_labels\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "\n",
    "def most_recent_file(directory, prefix):\n",
    "    \"\"\"Returns the most recently created file in the given directory with the specified prefix.\"\"\"\n",
    "    files = [f for f in os.listdir(directory) if f.startswith(prefix)]\n",
    "    if not files:\n",
    "        return None\n",
    "    return max([os.path.join(directory, f) for f in files], key=os.path.getctime)\n",
    "\n",
    "def train_and_save_models(clf_dir, symbol='ETHUSDT', timeframe='1h', retrain_time=datetime.timedelta(weeks=1)):\n",
    "    \n",
    "    recent_svc = most_recent_file(clf_dir, \"signal_clf_\")\n",
    "    recent_lof = most_recent_file(clf_dir, \"novelty_detection_\")\n",
    "    \n",
    "    retrain = False\n",
    "    \n",
    "    for model in [recent_svc, recent_lof]:\n",
    "        if not model:\n",
    "            retrain = True\n",
    "            break\n",
    "        \n",
    "        date_str = re.search(r'(\\d{4}\\d{2}\\d{2}_\\d{2}\\d{2}\\d{2})', model)\n",
    "        if date_str:\n",
    "            recent_date = datetime.datetime.strptime(date_str.group(1), '%Y%m%d_%H%M%S')\n",
    "            \n",
    "            # Überprüfen, ob retrain_time seit dem letzten Training vergangen ist\n",
    "            if datetime.datetime.now() - recent_date > retrain_time:\n",
    "                retrain = True\n",
    "                break\n",
    "    \n",
    "    if not retrain:\n",
    "        print(\"No retraining required!\")\n",
    "        return\n",
    "    \n",
    "    # Daten von Binance herunterladen\n",
    "    timerange = TRAIN_WINDOW_SIZE + 2 * max(feature_lookbacks)\n",
    "    df = fetch_binance_data(symbol=symbol, timeframe=timeframe, timerange=timerange)\n",
    "    \n",
    "    # Features und Labels extrahieren\n",
    "    df_with_feats = integrate_features_to_df(df)\n",
    "    df_with_feats_and_labels = add_labels(df_with_feats)\n",
    "    \n",
    "    # Daten vorbereiten\n",
    "    df_with_feats_and_labels = df_with_feats_and_labels.dropna(subset=['label'])\n",
    "    \n",
    "    print(\"training from\",df_with_feats_and_labels.iloc[0].Open_time )\n",
    "    print(\"training till\",df_with_feats_and_labels.iloc[-1].Open_time )\n",
    "    X = df_with_feats_and_labels[[col for col in df_with_feats_and_labels.columns if 'Feature' in col]]\n",
    "    y = df_with_feats_and_labels['label']\n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    # SVC-Classifier trainieren\n",
    "    svc_model = train_model_wf(X, y)\n",
    "    \n",
    "    # LOF-Modell trainieren\n",
    "    lof_model = train_lof_model(X)\n",
    "    \n",
    "    # Beide Modelle speichern\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    joblib.dump(svc_model, os.path.join(clf_dir, f\"signal_clf_{timestamp}.pkl\"))\n",
    "    joblib.dump(lof_model, os.path.join(clf_dir, f\"novelty_detection_{timestamp}.pkl\"))\n",
    "    print(f\"Models saved with timestamp {timestamp}\")\n",
    "\n",
    "\n",
    "def train_model_wf(X_train, y_train):\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(max_iter=1000000))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    return pipe\n",
    "\n",
    "def train_lof_model(X_train, contamination=0.0025):\n",
    "    lof = LocalOutlierFactor(novelty=True, contamination=contamination)\n",
    "    lof.fit(X_train)\n",
    "    return lof\n",
    "\n",
    "# Beispielaufruf:\n",
    "test_dir = \"testdir\"\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "retrain_time = datetime.timedelta(minutes=1)\n",
    "train_and_save_models(clf_dir=test_dir, symbol='ETHUSDT', timeframe='1h', retrain_time=retrain_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e995c7e-537e-4595-8f0a-f8439cc07aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testdir'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4e2f3f4-dc7a-45c3-8d1f-7a124f3a2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"tst.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b03dcf64-d4ff-49e1-ae36-40fa8eaad184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recent_models(clf_dir):\n",
    "    \"\"\"Load the most recent SVC and LOF models from the specified directory.\"\"\"\n",
    "\n",
    "    # Determine the most recent SVC and LOF models based on their filename prefixes\n",
    "    recent_svc_file = most_recent_file(clf_dir, \"signal_clf_\")\n",
    "    recent_lof_file = most_recent_file(clf_dir, \"novelty_detection_\")\n",
    "\n",
    "    if not recent_svc_file or not recent_lof_file:\n",
    "        print(\"Could not find models in the specified directory!\")\n",
    "        return None, None\n",
    "\n",
    "    # Load the models using joblib\n",
    "    svc_model = joblib.load(recent_svc_file)\n",
    "    lof_model = joblib.load(recent_lof_file)\n",
    "\n",
    "    return svc_model, lof_model\n",
    "\n",
    "svc_model, lof_model = load_recent_models(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec2b334-d00c-42fe-8611-0a4ce8ad35f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xyz\\anaconda3\\envs\\basic\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lof_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25bbdb9-36b9-49d8-96c6-525c9e6278b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_feats = integrate_features_to_df(df[[\"Close\", \"Volume\"]])\n",
    "df[\"Close\"] = df.Close.astype(\"float\")\n",
    "df[\"Volume\"] = df.Volume.astype(float)\n",
    "df_with_feats = integrate_features_to_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de974b37-a59a-4630-b995-a65d2a1bf1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      39427.524\n",
       "1      38991.601\n",
       "2      49293.709\n",
       "3      28408.226\n",
       "4      15179.287\n",
       "         ...    \n",
       "145    21764.488\n",
       "146    43936.229\n",
       "147    25778.054\n",
       "148    44918.421\n",
       "149    15865.812\n",
       "Name: Volume, Length: 150, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b84e052-d421-4302-a23f-257413396c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close time',\n",
       "       'Quote asset volume', 'Number of trades', 'Taker buy base asset volume',\n",
       "       'Taker buy quote asset volume', 'Ignore', 'Open_time', 'Close_time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns#.drop(\"Opentime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061551fd-6fc4-4215-9754-3325f00d77dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
